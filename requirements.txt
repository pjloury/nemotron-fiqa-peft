# Core dependencies for Nemotron Next 8B LoRA Fine-tuning with FiQA

# NeMo AutoModel
nemo-automodel>=0.2.0

# Transformers and PEFT
transformers>=4.40.0
peft>=0.8.0
accelerate>=0.30.0

# Data processing
datasets>=2.16.0

# Training utilities
torch>=2.0.0
tensorboard>=2.15.0

# Evaluation
sentence-transformers>=2.2.0  # Semantic similarity metrics
scikit-learn>=1.3.0  # Required for semantic similarity
nltk>=3.8.0  # Required for tokenization in metrics

# API server (optional, for serving model via API)
fastapi>=0.104.0
uvicorn[standard]>=0.24.0

# Optional but recommended
numpy>=1.24.0
tqdm>=4.66.0
